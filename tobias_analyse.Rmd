
<table>
<tr><td>
<div style="padding: 20px">
<div style="float:left; position:relative; width:50%">
```{r, echo=FALSE}
  adj_dpareto <- function(n, xi, l){
    return (1.116865 * dpareto(n, xi, l));
  }

  x <- seq(0, max(Boston$crim), 0.01)
  n <- length(Boston$crim)
  xi <- min(Boston$crim)
  l <- n / (sum (sapply(Boston$crim, function(x) log(x/xi))))
  hist(Boston$crim, main="Dichte von crim", freq = FALSE, nclass = 1000)
  y <- sapply(x, function(n) adj_dpareto(n,xi,l))
  lines(x, y, col="red")
```
</div>
Crim beschreibt die Verbrechensrate pro Einwohner einer Stadt. Die Größe lässt sich gut mit einer Pareto-Verteilung beschreiben. Die Parameter errechnen sich wie folgt:
$$ \hat \xi = min_{1 \leq i \leq n} \, x_i = 0.00632$$
$$ \hat \lambda = \frac{n}{\sum_{i=1}^n log \Big ( \frac{x_i}{\hat \xi}\Big)} =  0.00645905 $$
Die Pareto-Verteilung ereignet sich gut für Datensätze die sich über mehrere Größenordnungen erstrecken. Das ist hier der Fall, da $\frac{max}{min} \approx 14000$ ist. Diese Paretto-Verteilund ist jedoch auf dem Interval $(0, \infty]$ definiert ist, und unsere Daten nur im Interval $[\hat \xi, 100]$ auftreten können könnte man denken, dass hier auch eine Exponentialverteilung mit $\tau = \frac{1}{\overline X} = 0.2767382$ zur Beschreibung verwendet werden kann. Jedoch fällt diese Kurve zu schnell ab und die Verteilungsfunktion erzeugt bereits bei $F(17)$ Werte jenseits von 99%. Daher wird zu Beschreibung der Verteilung eine angepasste Pareto-Verteilung verwendet. Dabei wird die Verteilungsfunktion so konstruiert, dass $F(100) = 1$ gilt. Die normale Verteilungsfunktion $F_p$ hat den Wert $F_P(100) = 0.8953634$.
Nun konstruiert man die adjustierte Verteilungsfunktion $F = c F_p$, wobei $c$ der Reziprokwert von $F_P(100)$ ist. Daher gilt die Verteilungsfunktion
$$F(n) = 1.116865 F_P(n)$$
Die Dichtefunktion $F'(n)$ ist aufgrund der Linearität des Differenzialqoutienten $f(n) = 1.116865 f_P(n)$, wobei $f_P(n)$ die Dichtefunktion der Pareto-Verteilung mit den obigen Parametern ist.
</div>
</td></tr>
<tr><td>
<div style="padding: 20px">
<div style="float:left; position:relative; width:50%">
```{r, echo=FALSE}
  hist(Boston$zn, main="Dichte von zn", freq = FALSE, nclass = 50)
```
</div>
Zn beschreibt den Anteil der Wohngrundstücke für Grundstücke mit mehr als 25.000 sq.ft. Es gibt viele 0-Werte (ca. 73%). Die restlichen Werte scheinen keiner konkreten Verteilung zu folgen. Am ehesten würden sich 2 weitere skalierte (Da diese maximal ~0.27 als Summe haben dürften) Binomialverteilungen (die Werte für zn sind nur $z \in \{0, 1, ...99, 100\}$) mit den Mittelpunkten 20 und 80 eigenen, da es hier kleinere Spitzen in den Frequenzen gibt. Darüber hinaus könnte es auch eine Gleichverteilung im Intervall $[12.5; 100]$ sein.
</div>
</td></tr>
<tr><td>

<div style="padding: 20px">
<div style="float:left; position:relative; width:50%">
```{r, echo=FALSE}
  hist(Boston$indus, main="Dichte von indus", freq = FALSE, nclass = 50)
```
</div>
Indus beschreibt den Anteil der Industriefläche pro Stadt. Wenn man sich das Datenset ansieht, kann man erkennen, dass Werte öfters vorkommen (zb. 18.10 kommt 132 Mal vor). Daher nehmen wir an, dass mehrere Vororte zu einem Industriegebiet zusammengefasst wurden. Für jeden Ort, der Teil eines Industriegebietes ist, wurde der Wert des gesamten Industriegebietes verwendet. Wenn diese Größe mit Hilfe einer Funktion beschrieben werden soll, dann würde sich eine skalierte Normalverteilung mit $\mu = 6$ und eine skalierte Exponential-Verteilung (oder ähnliches) ab ca. $18$.
</div>
</td></tr>
<tr><td>

<div style="padding: 20px">
<div style="float:left; position:relative; width:50%">
Der Anteil der Städte aus der Stichprobe, welche am Charles River liegen.
```{r, echo=FALSE, result='hold'}
print(length(Boston$chas[Boston$chas == 1]) / length(Boston$chas))
```
Der Anteil der Städte aus der Stichprobe, welche nicht am Charles River liegen.
```{r, echo=FALSE, result='hold'}
print(length(Boston$chas[Boston$chas == 0]) / length(Boston$chas))
```
</div>
Chas gibt ab, ob der Vorort an den Charles River angrenzt. Hierbei handelt es sich um eine Bernoulli Verteilung. Die Wahrscheinlichkeit, dass das Bernoulli Experiment erfolgreich ist, lässt sich wie folgt berechnen: 
$$ \hat p = \frac{\hat p_t}{n} = 0.06916996$$
Wobei $\hat p_t$ die Anzahl der erfolgreichen Experimente in der Stichprobe ist.
</div>
</td></tr>
<tr><td>

<div style="padding: 20px">
<div style="float:left; position:relative; width:50%">
```{r, echo=FALSE}
q1 = quantile(Boston$nox,0.1);
q9 = quantile(Boston$nox,0.9);
mlog <- (log(q1) + log(q9)) / 2
percentile <- 0.1
slog <- (log(q1) - mlog) / qnorm(percentile)
plot(density(Boston$nox), col=3, main="Dichte von nox")
curve(dlnorm(x, meanlog = mlog, sdlog = slog, log = FALSE),add=TRUE,lwd=1, col="red")
box()
```
```{r, echo=FALSE}
qqnorm(sapply(Boston$nox, function(x) log(x)))
qqline(sapply(Boston$nox, function(x) log(x)), col="red")
n <- length(Boston$nox)
```
</div>
Nox gibt die Konzentration von Stickstoff-Oxiden an. Die Größe scheint nicht ganz normalverteilt zu sein, da die Dichtefunktion (siehe Plot links) nicht symmetrisch scheint - sie steigt stärker an, als sie abfällt. Daher wird versucht, die Größe mit einer logarithmischen Normalverteilung zu beschreiben. Die transformierte Zufallsvariable $Y = log(X)$ ist annähernd normalverteilt (siehe QQPlot). Jedoch ist das Ergebnis nur marginal besser, als durch eine normale Normalverteilung.
Um die Zufallsvariabel $Y$ analysieren zu können, wurde für jedes Element $x_i$ aus der Stichprobe $y_i = log(x_1)$ gesetzt. Der so gewonnene Datensatz repräsentiert nun eine Stichprobe der Zufallsvariable $Y$. 
</div>
</td></tr>
</table>
